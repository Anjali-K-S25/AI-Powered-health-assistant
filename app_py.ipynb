{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Anjali-K-S25/AI-Powered-health-assistant/blob/main/app_py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers torch accelerate gradio"
      ],
      "metadata": {
        "id": "8qctiHEVkZZF",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bitsandbytes\n",
        "import bitsandbytes\n",
        "print(\"‚úÖ bitsandbytes is installed correctly!\")"
      ],
      "metadata": {
        "id": "p_-PJ64wzgiX",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "\n",
        "print(\"‚è≥ Loading BioMistral-7B model in 8-bit mode...\")\n",
        "\n",
        "bnb_config = BitsAndBytesConfig(load_in_8bit=True)\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"BioMistral/BioMistral-7B\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"BioMistral/BioMistral-7B\",\n",
        "    quantization_config=bnb_config,  # Enable 8-bit mode\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Model loaded successfully in 8-bit mode!\")"
      ],
      "metadata": {
        "id": "-QfMkk820rFM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import gradio as gr\n",
        "\n",
        "# ‚úÖ Define Chatbot Function\n",
        "def chat_with_meditron(user_query):\n",
        "    if not user_query.strip():\n",
        "        return \"‚ö†Ô∏è Please enter a valid medical question.\"\n",
        "\n",
        "    try:\n",
        "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        inputs = tokenizer(user_query, return_tensors=\"pt\").to(device)\n",
        "\n",
        "        # **Optimized generation settings**\n",
        "        output = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=200,  # Restrict response length\n",
        "            temperature=0.5,  # More focused responses\n",
        "            top_p=0.8,  # Reduce hallucinations\n",
        "            repetition_penalty=1.2  # Avoid repeating phrases\n",
        "        )\n",
        "\n",
        "        response = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "\n",
        "        # **Filter out irrelevant answers**\n",
        "        if \"I'm sorry\" in response or len(response.split()) < 5:\n",
        "            return \"‚ö†Ô∏è I couldn't find a relevant medical answer. Please rephrase your question.\"\n",
        "\n",
        "        return response\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"‚ö†Ô∏è Error: {str(e)}\"\n",
        "\n",
        "# ‚úÖ Define Gradio UI\n",
        "with gr.Blocks(theme=gr.themes.Soft()) as app:\n",
        "    with gr.Tab(\"üè• Main Page\"):\n",
        "        gr.Markdown(\"<h1 style='text-align: center;'>üè• AI Health Assistant</h1>\")\n",
        "        gr.Markdown(\"<p style='text-align: center; font-size:18px;'>Ask any medical-related question and get AI-generated insights.</p>\")\n",
        "\n",
        "        user_input = gr.Textbox(label=\"Enter your medical query:\")\n",
        "        submit_button = gr.Button(\"üîç Get Answer\", variant=\"primary\")\n",
        "        chatbot_response = gr.Textbox(label=\"Chatbot Response\", interactive=False)\n",
        "\n",
        "        submit_button.click(chat_with_meditron, inputs=user_input, outputs=chatbot_response)\n",
        "\n",
        "    with gr.Tab(\"‚ÑπÔ∏è About\"):\n",
        "        gr.Markdown(\"<h2>‚ÑπÔ∏è About the AI Health Assistant</h2>\")\n",
        "        gr.Markdown(\"- üè• This AI chatbot answers **medical-related questions**.\\n- ‚ö†Ô∏è **Not a substitute for professional medical advice**.\\n- üöÄ Built using **Gradio** and **Hugging Face Models**.\")\n",
        "\n",
        "    with gr.Tab(\"‚ùì FAQ\"):\n",
        "        gr.Markdown(\"<h2>‚ùì Frequently Asked Questions</h2>\")\n",
        "\n",
        "        gr.Markdown(\"**1Ô∏è‚É£ Can I use this for medical diagnosis?**\\n- ‚ùå No, this is for **informational purposes only**. Always consult a healthcare professional for medical concerns.\")\n",
        "\n",
        "        gr.Markdown(\"**2Ô∏è‚É£ How accurate are the responses?**\\n- üìä The AI provides answers based on trained medical data, but accuracy depends on the complexity of the question. Cross-check with reliable sources.\")\n",
        "\n",
        "        gr.Markdown(\"**3Ô∏è‚É£ Is my data safe?**\\n- üîê Yes, your input is **not stored**. This chatbot runs locally or through a secure cloud instance.\")\n",
        "\n",
        "        gr.Markdown(\"**4Ô∏è‚É£ What types of medical questions can I ask?**\\n- üí° You can ask about **symptoms, diseases, medications, treatments, and general health advice**. However, it does **not replace professional medical consultation**.\")\n",
        "\n",
        "        gr.Markdown(\"**5Ô∏è‚É£ Does this AI prescribe medicine?**\\n- ‚ùå No, this chatbot does **not prescribe medications**. Always consult a doctor before taking any medicine.\")\n",
        "\n",
        "        gr.Markdown(\"**6Ô∏è‚É£ Can it provide emergency medical advice?**\\n- ‚ö†Ô∏è No, this AI is **not for emergency situations**. If you have a medical emergency, please call **emergency services immediately**.\")\n",
        "\n",
        "        gr.Markdown(\"**7Ô∏è‚É£ Is the chatbot suitable for mental health support?**\\n- üß† While it can provide **basic mental health guidance**, it is **not a substitute for professional therapy**. If you're struggling, seek help from a mental health professional.\")\n",
        "\n",
        "        gr.Markdown(\"**8Ô∏è‚É£ Can I trust the medical advice given?**\\n- üè• The AI provides information based on medical sources, but it should **not be your only source**. Always verify with medical professionals or trusted resources like the **WHO or CDC**.\")\n",
        "\n",
        "        gr.Markdown(\"**9Ô∏è‚É£ How frequently is the AI updated?**\\n- üîÑ The AI model is periodically updated based on available **medical research** and **AI improvements**. However, it's always best to **cross-check medical advice**.\")\n",
        "\n",
        "        gr.Markdown(\"**üîü Can I use this chatbot for educational purposes?**\\n- üìö Yes! This chatbot is great for **learning about medical topics** but should not be used for clinical decision-making.\")\n",
        "\n",
        "# ‚úÖ Launch the app\n",
        "app.launch(share=True)"
      ],
      "metadata": {
        "id": "2EQ2enwn5usc"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNBCOiFxHWNPdCN6SI9r5ux",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}